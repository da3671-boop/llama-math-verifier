| **Experiment**   | **Model**                  | **Training Samples** | **LoRA Config (r, α)** | **Remarks**                                                           |
| ---------------- | -------------------------- | -------------------- | ---------------------- | --------------------------------------------------------------------- |
| **Experiment 1** | Meta-Llama-3.1-8B          | 5 000                | (16, 32)               | Baseline setup provided for initial evaluation. |
| **Experiment 2** | Meta-Llama-3.1-8B-Instruct | 20 000               | (16, 32)               | Extended training on larger dataset using instruct-tuned model.       |
| **Experiment 3** | Meta-Llama-3.1-8B          | 25 000               | (32, 64)               | **Final configuration submitted to Kaggle** — best performing model.  |

